[{"id":"e346a4b057af7bc50ce0cb6886d2aa96","title":"Spark","content":"采用RDD模型批计算，将DAG划分为不同的stagespark streaming:\n","slug":"Spark","date":"2022-05-17T01:51:50.000Z","categories_index":"","tags_index":"Knowledge","author_index":"Zoey"},{"id":"e3edccc88bdb962a2f18d70775d79554","title":"Flink","content":"What is Apache Flink?Apache FlinkApache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale.\nApplication scenarios\n实时报表\n广告投放\n实施推荐\n实时数据采集\n信息推送\n订单状态跟踪\n实时结算\n实时报警\n风险检测\n\nLambda架构设计理念Lambda架构的设计是为了在处理大规模数据时，同时发挥流处理和批处理的优势。通过批处理提供全面、准确的数据，通过流处理提供低延迟的数据，从而达到平衡延迟、吞吐量和容错性的目的。为了满足下游的即席查询，批处理和流处理的结果会进行合并。\n组成\nBatch Layer：批处理层\nSpeed Layer：加速处理层\nServing Layer：服务层、合并层\n\n系统架构\nExactly-Once语义发送到消息系统的消息只能被消费端处理且仅处理一次，Exactly-Once语义是消息系统和流式计算系统中消息流转的最理想状态，但是在业界并没有太多理想的实现。因为真正意义上的Exactly-Once依赖消息系统的服务端、消息系统的客户端和用户消费逻辑这三者状态的协调。例如，当您的消费端完成一条消息的消费处理后出现异常宕机，而消费端重启后由于消费的位点没有同步到消息系统的服务端，该消息有可能被重复消费。\n","slug":"Flink","date":"2022-05-17T01:50:05.000Z","categories_index":"","tags_index":"Knowledge","author_index":"Zoey"},{"id":"f6c5ab269c53087419eb1c0be5e917d0","title":"Flume","content":"是什么？高可用、高可靠、分布式的海量日志采集、聚合、传输系统。Flume基于流式架构，灵活简单，实时的动态采集。能够采集多种形式源数据文件、socket数据包、kafka等，输出到HDFS、HBase、Hive、kafka等。\n由Flume OG–&gt;到Flume NG:Flume OG:(核心组件设计不合理、代码工程臃肿、核心配置不标准，尤其是日志传输不稳定)\n\nagent(代理节点)：从数据源收集日志数据\ncollector(收集节点)：集中收集的日志文件，存入HDFS\nmaster(主节点)：管理agent、collector的活动\n\nFlume NG:(重构核心组件、核心配置、代码架构)\n\n取消了Master、Zookeeper–&gt;纯粹的传输工具\nagent(代理节点)：source + sink + Channel\n\n组成架构\n\n\n\n\n\n\n\n\n\n\n\nEvent:数据传输基本单位。Headers(Event属性) + Body(数据)Agent(核心):一个JVM(Java Virtual Machine)进程,获取数据，将数据封装成Event(事件)，输送到目的地。\n\nSource:采集组件，跟数据源对接，获取数据。\nChannel:传输通道，缓冲区[允许Source和Sink不同速率的运行]，能处理多个Source写入操作和sink读取操作。自带两种Channel:\n\nMemory Channel:内存中的队列，适用于不关心数据丢失的情景。\n\n\n\nFile Channel:写入磁盘中，程序关闭和机器宕机不会丢失数据。\n\n\nSink:下沉组件，向下一个agent传递数据 或者 传输到最终存储系统中。不断轮询Channel中Event且批量移除。\n\n\n做什么？\n复制\n多路复用\n负载均衡\n故障转移\n聚合\n\n","slug":"Flume","date":"2022-05-12T11:20:05.000Z","categories_index":"","tags_index":"Knowledge","author_index":"Zoey"},{"id":"40cdd8f377648aa5f834443bc2499b7f","title":"Expand","content":"HDFSHDFS读写流程\nMapReduceMapReduce流程图\n\n\n\n\n\n\n\n\n\ninput文件存储在HDFS中，切块Block(128M)，默认3个备份存储在多个节点中MR通过Inputformat，读取数据从HDFS\n\n\n\n\n\n\n\n\n\nSplitting读取后切片Split，Split的数量由Block决定split大小由minSize、maxSize、blockSize决定\n\n\n\n\n\n\n\n\n\nMapperMap个数由Split决定，一个Split分配一个MapTaskMap()函数处理数据，会输出一组key&#x2F;value对，编写MR程序的Map函数，现在使用Hive SQL代替MR\nMap之后，数据进入分区方法，标记好分区，发送给环形缓冲区(128M buffer in memory)，溢写前对数据排序(key索引:字典排序:快速排序)，达到80%，进行溢写，溢写文件排序(归并排序)，按照分区存储到磁盘。\n\n\n\n\n\n\n\n\n\nShuffle不需要编写但关键Shuffle将相同key&#x2F;value对组合在一起(Combiner阶段)，传给Reduce主机\n每个Reduce拉取Map对应分区数据，数据存到内存，内存不够存到磁盘。将内存和磁盘数据都归并排序，可对数据分组操作。整个Shuffle三次排序。\n\n\n\n\n\n\n\n\n\nReduceReduce()函数处理key&#x2F;value，合并相同key的value值，产生另外的key&#x2F;value对，输入到HDFS。\nYarn核心思想：ResourceManager和ApplicationMaster将整个功能分开\n\nHiveFaceBook为解决海量数据的统计分析，基于Hadoop开发的数据分析工具。Hive没有存储能力，只有使用数据的能力。\n\n\n\n\n\n\n\n\n\n将结构化数据文件映射成数据库表。Hive是数仓工具，数据从HDFS获得，不能直接数据访问HDFS，通过MR实现。本质：将HQL语句转换为MR任务，进行数据访问。根据业务编写SQl语句，自动地匹配Hive封装的MR，运行MR生成分析结果。\nHive中(元数据)Meradata:Hive表和数据的映射关系，有Hive创建的Database、table、分区、属性、表的数据所在目录等元数据。元数据存储在Derby或者第三方MySQL中。Hive元数据不断更新修改，HDFS文件多读少改，所以元数据不能存储在HDFS，只能存储在数据库中Metastore:元数据服务,Hive管理库表元数据。\nZookeeperGoogle的Chubby的，分布式应用程序协调服务。监听：Znode节点的数据变化，子节点的增减变化\n\n统一配置管理：从系统A、B、C的配置中抽取其中相同的配置文件common.yml，即使改变不需重启。\n统一命名服务：为有一部分资源命名，通过名字访问资源。\n分布式锁：Java锁？分布式锁？乐观锁？行锁？\n判断自己是不是最小的节点\n- 是，拿到锁\n- - 执行完，删除节点，释放锁\n- 否，监听比自己小的节点\n集群管理：Zookeeper动态选举Master，Znode节点类型是顺序临时节点，选举最小作为Master。挂机后Znode节点删除，新的最小作为Master。系统A挂机，A的节点删除，通过监听节点，系统B、C感知系统A挂机。\n\nHBaseHBase是Google BigTable的，面向列、稀疏、随机访问、实时读写、存储检索数据的NoSQL分布式数据库。不是关系型，不支持SQL，数据分析能力弱\n\n\n\n\n\n\n\n\n\n数据结构:\n\nTable:表，由列族组成\nRow Key:数据记录的唯一标识，按字典排序\nColumn Family:列族，同一列族存储在同一目录\nColumn Qualifier:列\nTimestamp:时间戳&#x2F;版本号\nCell:单元格\n\nColumn&#x3D; Column Family:Column Qualifierkey   &#x3D; rowkey,column,timestamp,typeCell  &#x3D; rowkey,column,timestamp,type,value\n\n写过程\n\n客户端向RegionServer发送写请求，客户端先从缓存中定位Region，否则访问Zookeeper，从META表获取Region信息。\n访问的对应的RegionServer，把数据写入HLog(WAL)和MemStore。WAL存储在HDFS中，通过WAL还原数据\nMemStore达到阈值–(flush)–&gt;(HDFS)StoreFile,底层由HFile格式存储。在Hlog文件中写一个标记，MemStore丢失，从HLog恢复\n多个StoreFlie达到阈值–(compact合并)–&gt;一个大的StoreFlie。版本合并和数据删除单个StoreFlie大小超过阈值–(split)–&gt;把Region拆成两个。HMaster分配到两个相应的RegionServer上读过程\n客户端访问Zookeeper，从META表获取Region信息(位置)\n向对应的RegionServer建立连接，发起读取数据请求。\nRegionServer先到MemStore中查数据，否则就到BlockCache中查，最后到磁盘HFlie中查。\n\nTomcat免费、轻量的Web应用服务器。\n\n\n\n\n\n组件\n功能\n\n\n\nService\n对外提供Web服务。\n\n\nConnector\n对外接收请求，监听端口，将请求处理后传递给容器，最后将结果反馈给外界。\n\n\nContainer\n对内处理业务，用于股那里和调用Servlet相关逻辑。\n\n\nProtocolHandler\n协议处理器，不同组合的封装。\n\n\nEndpoint\n端点，处理Socket接收和发送的逻辑。Accept监听请求，Handler处理数据，AsyncTimeout检查请求超时。\n\n\nProcessor\n处理器，构建Tomcat的Request和Response对象。\n\n\nAdapter\n适配器，实现Tomcat Request、Response与Servlet Request、Response的转换。\n\n\nEngine\n引擎，管理多个虚拟主机。\n\n\nHost\n虚拟主机，部署Web应用。\n\n\nContext\nWeb应用，包含多个Servlet封装器。\n\n\nWrapper\n封装器，对Servlet封装，创建实例，执行、销毁。\n\n\nRedisC语言开发，内存数据库。读写效率极高，持久化、缓存、键值对(KV)、NoSQL数据库、单线程、I&#x2F;O，支持多种数据类型。Redis持久化：\n\nRDB：快照形式，直接把内存中数据保存到一个dump.rdb文件中。\nAOF：所有对Redis服务器进行修改的命令存到一个文件里。只追加不改写。\n\n会话缓存消息队列排行榜发布订阅商品评论\n","slug":"Expand","date":"2022-05-12T09:03:17.000Z","categories_index":"","tags_index":"Knowledge","author_index":"Zoey"},{"id":"1ba3f6b8c00820b856963241fb70d957","title":"MD","content":"Tip Container\n\n\n\n\n\nName\n\nwrite\nread:::\n\nDanger Container:::dangerdanger!!!\n\nWarning Container\n\n\n\n\n\n\n注意\nWarning!!!\n\nDetails Container\nClick to see\nwrite some details\nconsole.log(&#39;bye&#39;)\n\n\nThe content shown above is very beautiful\n","slug":"MD","date":"2022-05-10T12:50:38.000Z","categories_index":"","tags_index":"method","author_index":"Zoey"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-05-10T01:57:59.433Z","categories_index":"","tags_index":"","author_index":"Zoey"}]
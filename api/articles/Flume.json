{"title":"Flume","uid":"f6c5ab269c53087419eb1c0be5e917d0","slug":"Flume","date":"2022-05-12T11:20:05.000Z","updated":"2022-05-15T13:52:30.479Z","comments":true,"path":"api/articles/Flume.json","keywords":null,"cover":[],"content":"<h1 id=\"是什么？\"><a href=\"#是什么？\" class=\"headerlink\" title=\"是什么？\"></a>是什么？</h1><p>高可用、高可靠、分布式的海量日志采集、聚合、传输系统。Flume基于流式架构，灵活简单，实时的动态采集。<br>能够采集多种形式源数据<u>文件、socket数据包、kafka</u>等，输出到<u>HDFS、HBase、Hive、kafka</u>等。</p>\n<h2 id=\"由Flume-OG–-gt-到Flume-NG\"><a href=\"#由Flume-OG–-gt-到Flume-NG\" class=\"headerlink\" title=\"由Flume OG–&gt;到Flume NG:\"></a>由<code>Flume OG</code>–&gt;到<code>Flume NG</code>:</h2><p><strong>Flume OG</strong>:(核心组件设计不合理、代码工程臃肿、核心配置不标准，尤其是日志传输不稳定)</p>\n<ul>\n<li>agent(代理节点)：从数据源收集日志数据</li>\n<li>collector(收集节点)：集中收集的日志文件，存入HDFS</li>\n<li>master(主节点)：管理agent、collector的活动</li>\n</ul>\n<p><strong>Flume NG</strong>:(重构核心组件、核心配置、代码架构)</p>\n<ul>\n<li>取消了Master、Zookeeper–&gt;纯粹的传输工具</li>\n<li>agent(代理节点)：source + sink + Channel</li>\n</ul>\n<h2 id=\"组成架构\"><a href=\"#组成架构\" class=\"headerlink\" title=\"组成架构\"></a>组成架构</h2><img src=\"../img/2022-05-12-20-56-51.png\" width=\"85%\">\n<img src=\"../img/2022-05-12-21-13-24.png\" width=\"85%\">\n\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Event:数据传输基本单位。Headers(Event属性) + Body(数据)<br><strong>Agent</strong>(核心):一个JVM(Java Virtual Machine)进程,获取数据，将数据封装成Event(事件)，输送到目的地。</p>\n<ul>\n<li>Source:采集组件，跟数据源对接，获取数据。</li>\n<li>Channel:传输通道，缓冲区[允许Source和Sink不同速率的运行]，能处理多个Source写入操作和sink读取操作。<br>自带两种Channel:</li>\n<li><ul>\n<li>Memory Channel:内存中的队列，适用于不关心数据丢失的情景。</li>\n</ul>\n</li>\n<li><ul>\n<li>File Channel:写入磁盘中，程序关闭和机器宕机不会丢失数据。</li>\n</ul>\n</li>\n<li>Sink:下沉组件，向下一个agent传递数据 或者 传输到最终存储系统中。<br>不断轮询Channel中Event且批量移除。</li>\n</ul></blockquote>\n<p><img src=\"../img/2022-05-15-16-39-55.png\"></p>\n<h1 id=\"做什么？\"><a href=\"#做什么？\" class=\"headerlink\" title=\"做什么？\"></a>做什么？</h1><ol>\n<li>复制</li>\n<li>多路复用</li>\n<li>负载均衡</li>\n<li>故障转移</li>\n<li>聚合</li>\n</ol>\n","feature":true,"text":"是什么？高可用、高可靠、分布式的海量日志采集、聚合、传输系统。Flume基于流式架构，灵活简单，实时的动态采集。能够采集多种形式源数据文件、socket数据包、kafka等，输出到HDFS、HBase、Hive、kafka等。 由Flume OG–&gt;到Flume NG:Fl...","link":"","photos":[],"count_time":{"symbolsCount":774,"symbolsTime":"1 mins."},"categories":[],"tags":[{"name":"Knowledge","slug":"Knowledge","count":4,"path":"api/tags/Knowledge.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F\"><span class=\"toc-text\">是什么？</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%94%B1Flume-OG%E2%80%93-gt-%E5%88%B0Flume-NG\"><span class=\"toc-text\">由Flume OG–&gt;到Flume NG:</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">组成架构</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%81%9A%E4%BB%80%E4%B9%88%EF%BC%9F\"><span class=\"toc-text\">做什么？</span></a></li></ol>","author":{"name":"Zoey","slug":"zoey","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"love music,love life~","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Flink","uid":"e3edccc88bdb962a2f18d70775d79554","slug":"Flink","date":"2022-05-17T01:50:05.000Z","updated":"2022-05-17T01:50:37.893Z","comments":true,"path":"api/articles/Flink.json","keywords":null,"cover":[],"text":"What is Apache Flink?Apache FlinkApache Flink is a framework and distributed processing engine for stateful computations over unbounded and ...","link":"","photos":[],"count_time":{"symbolsCount":772,"symbolsTime":"1 mins."},"categories":[],"tags":[{"name":"Knowledge","slug":"Knowledge","count":4,"path":"api/tags/Knowledge.json"}],"author":{"name":"Zoey","slug":"zoey","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"love music,love life~","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Expand","uid":"40cdd8f377648aa5f834443bc2499b7f","slug":"Expand","date":"2022-05-12T09:03:17.000Z","updated":"2022-05-12T09:22:38.887Z","comments":true,"path":"api/articles/Expand.json","keywords":null,"cover":[],"text":"HDFSHDFS读写流程 MapReduceMapReduce流程图 input文件存储在HDFS中，切块Block(128M)，默认3个备份存储在多个节点中MR通过Inputformat，读取数据从HDFS Splitting读取后切片Split，Split的数量由Block决...","link":"","photos":[],"count_time":{"symbolsCount":"2.9k","symbolsTime":"3 mins."},"categories":[],"tags":[{"name":"Knowledge","slug":"Knowledge","count":4,"path":"api/tags/Knowledge.json"}],"author":{"name":"Zoey","slug":"zoey","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"love music,love life~","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}